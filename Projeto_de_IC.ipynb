{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Projeto de IC",
      "provenance": [],
      "authorship_tag": "ABX9TyOJlAyz/UoU//yE4+yr40Tw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cleycianefarias/Rede-Neural-MLP/blob/main/Projeto_de_IC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wt1uhm7urbM7"
      },
      "source": [
        "from __future__ import print_function\r\n",
        "from builtins import range\r\n",
        "import pandas as pd"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0z-bDqzGrkCR"
      },
      "source": [
        "\r\n",
        "\"\"\"\r\n",
        "SECTION 1: carregar e treinar os dados da base\r\n",
        "os conjuntos de dados foram separados em dois para executar o treinamento dos dados\r\n",
        "country.csv = conjuntos de dados para fins de treinamento, 70% dos dados originais\r\n",
        "train.csv  = conjuntos de dados para fins de teste, 30% dos dados originais\r\n",
        "\"\"\"\r\n",
        "#Carregamento dos dados\r\n",
        "datatrain = pd.read_csv('/content/country.csv')\r\n",
        "\r\n",
        "#alterar o valor da String para numérico\r\n",
        "datatrain.loc[datatrain['status']=='Closed', 'status']=0\r\n",
        "datatrain.loc[datatrain['status']=='Merged', 'status']=1\r\n",
        "datatrain = datatrain.apply(pd.to_numeric)\r\n",
        "\r\n",
        "#alterando o dataframe para o array \r\n",
        "datatrain_array = datatrain.values\r\n",
        "\r\n",
        "#dividir x e y (recurso e destino)\r\n",
        "xtrain = datatrain_array[:,:18]\r\n",
        "ytrain = datatrain_array[:,18]\r\n",
        "\r\n",
        "print(\"Deu certo\")\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfHAFq0jsnJX"
      },
      "source": [
        "\"\"\"\r\n",
        "SECTION 2 : Construindo e treinando o modelo de adaptação da rede mlp\r\n",
        "Multilayer perceptron model (MLP).\r\n",
        "input layer : 18 neuron, representa as principais caracteristicas da base\r\n",
        "hidden layer : 1 neuron, ativação usando ReLU\r\n",
        "output layer : 3 neuron, representa a classe do status final de aceitação/rejeição, Softmax Layer\r\n",
        "optimizer = descida gradiente estocástica sem tamanho de lote\r\n",
        "loss function = entropia cruzada categórica\r\n",
        "learning rate = default from keras.optimizer.SGD, 0.01\r\n",
        "epoch = 500\r\n",
        "\"\"\"\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow.keras.layers import Dense, Activation\r\n",
        "from tensorflow.keras.utils import to_categorical\r\n",
        "\r\n",
        "#mudar o formato do alvo\r\n",
        "ytrain = to_categorical(ytrain) \r\n",
        "\r\n",
        "#Construindo o modelo\r\n",
        "model = tf.keras.Sequential()\r\n",
        "model.add(Dense(1, input_shape=(18,)))\r\n",
        "model.add(Activation(\"relu\"))\r\n",
        "model.add(Dense(2))\r\n",
        "model.add(Activation(\"softmax\"))\r\n",
        "\r\n",
        "#escolhendo o otimizador e a função de perda\r\n",
        "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\r\n",
        "\r\n",
        "#treinando o modelo\r\n",
        "model.fit(xtrain, ytrain, epochs=500, batch_size=32)\r\n",
        "print(\"parece que funcionou\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdGwnHfDt84g"
      },
      "source": [
        "\r\n",
        "\"\"\"\r\n",
        "SECTION 3 : Testando o modelo\r\n",
        "\"\"\"\r\n",
        "#carregando o modelo\r\n",
        "datatest = pd.read_csv('/content/train.csv')\r\n",
        "\r\n",
        "datatest.loc[datatest['status']=='Closed', 'status']=0\r\n",
        "datatest.loc[datatest['status']=='Merged', 'status']=1\r\n",
        "datatest = datatest.apply(pd.to_numeric)\r\n",
        "\r\n",
        "#mudando o dataframe para array\r\n",
        "datatest_array = datatest.values\r\n",
        "\r\n",
        "#dividir x e y (recurso e destino)\r\n",
        "xtest = datatest_array[:,:18]\r\n",
        "ytest = datatest_array[:,18]\r\n",
        "\r\n",
        "#pegando a predição\r\n",
        "classes = model.predict_classes(xtest, batch_size=32)\r\n",
        "\r\n",
        "#pegando o valor da aurácia de treinamento\r\n",
        "import numpy as np\r\n",
        "accuration = np.sum(classes == ytest)/len(ytest) * 100\r\n",
        "\r\n",
        "print(\"Test Accuration : \" + str(accuration) + '%')\r\n",
        "print(\"Prediction :\")\r\n",
        "print(classes)\r\n",
        "print(\"Target :\")\r\n",
        "print(np.asarray(ytest,dtype=\"int32\"))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}